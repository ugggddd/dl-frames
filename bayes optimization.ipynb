{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> 贝叶斯优化 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一.高斯过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=999)\n",
    "\n",
    "clf = GaussianNB()\n",
    "#拟合数据\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二. sklearn 贝叶斯优化 使用案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 产生随机分类数据集，10个特征， 2个类别\n",
    "x, y = make_classification(n_samples=1000,n_features=10,n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.988395\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "print(np.mean(cross_val_score(rf, x, y, cv=20, scoring='roc_auc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_cv(n_estimators, min_samples_split, max_features, max_depth):\n",
    "    val = cross_val_score(\n",
    "        RandomForestClassifier(n_estimators=int(n_estimators),\n",
    "            min_samples_split=int(min_samples_split),\n",
    "            max_features=min(max_features, 0.999), # float\n",
    "            max_depth=int(max_depth),\n",
    "            random_state=2\n",
    "        ),\n",
    "        x, y, scoring='roc_auc', cv=5\n",
    "    ).mean()\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_bo = BayesianOptimization(\n",
    "        rf_cv,\n",
    "        {'n_estimators': [10, 100],\n",
    "        'min_samples_split': [2, 10],\n",
    "        'max_features': [0.1, 0.5],\n",
    "        'max_depth': [5, 10]\n",
    "    }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | max_fe... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9885  \u001b[0m | \u001b[0m 8.997   \u001b[0m | \u001b[0m 0.2599  \u001b[0m | \u001b[0m 8.029   \u001b[0m | \u001b[0m 56.84   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.9847  \u001b[0m | \u001b[0m 5.119   \u001b[0m | \u001b[0m 0.1971  \u001b[0m | \u001b[0m 7.079   \u001b[0m | \u001b[0m 30.91   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.9881  \u001b[0m | \u001b[0m 7.042   \u001b[0m | \u001b[0m 0.108   \u001b[0m | \u001b[0m 9.42    \u001b[0m | \u001b[0m 96.77   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.9866  \u001b[0m | \u001b[0m 7.069   \u001b[0m | \u001b[0m 0.1798  \u001b[0m | \u001b[0m 3.799   \u001b[0m | \u001b[0m 67.93   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9874  \u001b[0m | \u001b[0m 6.132   \u001b[0m | \u001b[0m 0.1444  \u001b[0m | \u001b[0m 7.82    \u001b[0m | \u001b[0m 43.33   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.991   \u001b[0m | \u001b[95m 9.209   \u001b[0m | \u001b[95m 0.339   \u001b[0m | \u001b[95m 2.502   \u001b[0m | \u001b[95m 99.88   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.991   \u001b[0m | \u001b[0m 9.555   \u001b[0m | \u001b[0m 0.3138  \u001b[0m | \u001b[0m 2.119   \u001b[0m | \u001b[0m 99.76   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9902  \u001b[0m | \u001b[0m 9.797   \u001b[0m | \u001b[0m 0.2576  \u001b[0m | \u001b[0m 8.738   \u001b[0m | \u001b[0m 99.95   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.991   \u001b[0m | \u001b[0m 9.058   \u001b[0m | \u001b[0m 0.3934  \u001b[0m | \u001b[0m 2.014   \u001b[0m | \u001b[0m 99.6    \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9903  \u001b[0m | \u001b[0m 9.955   \u001b[0m | \u001b[0m 0.2834  \u001b[0m | \u001b[0m 2.188   \u001b[0m | \u001b[0m 99.41   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.9905  \u001b[0m | \u001b[0m 5.232   \u001b[0m | \u001b[0m 0.3179  \u001b[0m | \u001b[0m 2.017   \u001b[0m | \u001b[0m 99.49   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.9905  \u001b[0m | \u001b[0m 6.012   \u001b[0m | \u001b[0m 0.331   \u001b[0m | \u001b[0m 9.896   \u001b[0m | \u001b[0m 99.98   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.9906  \u001b[0m | \u001b[0m 5.051   \u001b[0m | \u001b[0m 0.4847  \u001b[0m | \u001b[0m 2.171   \u001b[0m | \u001b[0m 99.71   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.9903  \u001b[0m | \u001b[0m 9.82    \u001b[0m | \u001b[0m 0.2508  \u001b[0m | \u001b[0m 2.187   \u001b[0m | \u001b[0m 99.89   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.9899  \u001b[0m | \u001b[0m 9.884   \u001b[0m | \u001b[0m 0.2896  \u001b[0m | \u001b[0m 9.794   \u001b[0m | \u001b[0m 99.55   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.9877  \u001b[0m | \u001b[0m 5.033   \u001b[0m | \u001b[0m 0.2575  \u001b[0m | \u001b[0m 2.386   \u001b[0m | \u001b[0m 99.73   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.9907  \u001b[0m | \u001b[0m 9.157   \u001b[0m | \u001b[0m 0.3072  \u001b[0m | \u001b[0m 9.817   \u001b[0m | \u001b[0m 99.79   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.9904  \u001b[0m | \u001b[0m 9.856   \u001b[0m | \u001b[0m 0.4707  \u001b[0m | \u001b[0m 8.829   \u001b[0m | \u001b[0m 99.96   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.989   \u001b[0m | \u001b[0m 9.74    \u001b[0m | \u001b[0m 0.178   \u001b[0m | \u001b[0m 8.633   \u001b[0m | \u001b[0m 99.77   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.9903  \u001b[0m | \u001b[0m 9.931   \u001b[0m | \u001b[0m 0.2007  \u001b[0m | \u001b[0m 2.399   \u001b[0m | \u001b[0m 99.99   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.9887  \u001b[0m | \u001b[0m 9.145   \u001b[0m | \u001b[0m 0.1373  \u001b[0m | \u001b[0m 2.025   \u001b[0m | \u001b[0m 99.76   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.9907  \u001b[0m | \u001b[0m 9.79    \u001b[0m | \u001b[0m 0.3954  \u001b[0m | \u001b[0m 9.344   \u001b[0m | \u001b[0m 99.98   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.9899  \u001b[0m | \u001b[0m 9.905   \u001b[0m | \u001b[0m 0.2199  \u001b[0m | \u001b[0m 9.738   \u001b[0m | \u001b[0m 99.77   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.987   \u001b[0m | \u001b[0m 5.071   \u001b[0m | \u001b[0m 0.273   \u001b[0m | \u001b[0m 9.629   \u001b[0m | \u001b[0m 99.85   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.9887  \u001b[0m | \u001b[0m 9.789   \u001b[0m | \u001b[0m 0.1782  \u001b[0m | \u001b[0m 2.085   \u001b[0m | \u001b[0m 99.82   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.9903  \u001b[0m | \u001b[0m 9.909   \u001b[0m | \u001b[0m 0.2088  \u001b[0m | \u001b[0m 2.661   \u001b[0m | \u001b[0m 99.26   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.9903  \u001b[0m | \u001b[0m 9.63    \u001b[0m | \u001b[0m 0.2855  \u001b[0m | \u001b[0m 2.15    \u001b[0m | \u001b[0m 99.05   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.9902  \u001b[0m | \u001b[0m 9.886   \u001b[0m | \u001b[0m 0.4456  \u001b[0m | \u001b[0m 2.523   \u001b[0m | \u001b[0m 99.88   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.9903  \u001b[0m | \u001b[0m 9.652   \u001b[0m | \u001b[0m 0.2679  \u001b[0m | \u001b[0m 2.468   \u001b[0m | \u001b[0m 99.76   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.9887  \u001b[0m | \u001b[0m 9.878   \u001b[0m | \u001b[0m 0.1037  \u001b[0m | \u001b[0m 2.529   \u001b[0m | \u001b[0m 99.27   \u001b[0m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "rf_bo.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.9917291809180918,\n",
       " 'params': {'max_depth': 7.805137623288971,\n",
       "  'max_features': 0.3695655852991595,\n",
       "  'min_samples_split': 2.9263805056874252,\n",
       "  'n_estimators': 249.57319688350591}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_bo.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: \n",
      "\t{'target': 0.9889771647164716, 'params': {'max_depth': 6.893182598099855, 'max_features': 0.5991968134251776, 'min_samples_split': 18.36382269893527, 'n_estimators': 102.47549659456831}}\n",
      "Iteration 1: \n",
      "\t{'target': 0.9870093309330933, 'params': {'max_depth': 8.394267888570939, 'max_features': 0.9600138277027127, 'min_samples_split': 6.089463692975234, 'n_estimators': 10.514162943770726}}\n",
      "Iteration 2: \n",
      "\t{'target': 0.9901545424542455, 'params': {'max_depth': 7.149097161768745, 'max_features': 0.4711225567635189, 'min_samples_split': 2.130241382853619, 'n_estimators': 249.7795342945158}}\n",
      "Iteration 3: \n",
      "\t{'target': 0.9896797589758975, 'params': {'max_depth': 12.196698592769122, 'max_features': 0.7101357468886657, 'min_samples_split': 24.069009748820644, 'n_estimators': 249.60070230186835}}\n",
      "Iteration 4: \n",
      "\t{'target': 0.9917291809180918, 'params': {'max_depth': 7.805137623288971, 'max_features': 0.3695655852991595, 'min_samples_split': 2.9263805056874252, 'n_estimators': 249.57319688350591}}\n",
      "Iteration 5: \n",
      "\t{'target': 0.9893281468146814, 'params': {'max_depth': 9.852461565970774, 'max_features': 0.40388006991303393, 'min_samples_split': 24.984396573537733, 'n_estimators': 249.26833176587647}}\n",
      "Iteration 6: \n",
      "\t{'target': 0.9897165626562657, 'params': {'max_depth': 7.951251608242572, 'max_features': 0.789106235327199, 'min_samples_split': 2.824973159844283, 'n_estimators': 249.1987242806842}}\n"
     ]
    }
   ],
   "source": [
    "for i, res in enumerate(rf_bo.res):\n",
    "    print(\"Iteration {}: \\n\\t{}\".format(i, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_bo.probe(\n",
    "    params={'n_estimators': 10,\n",
    "        'min_samples_split': 2,\n",
    "        'max_features': 0.5,\n",
    "        'max_depth': 5\n",
    "    },\n",
    "    lazy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | max_fe... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.9871  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.9871  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.9871  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "rf_bo.maximize(init_points=0, n_iter=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三. 深度学习 贝叶斯优化使用案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NFtorch.DeepLearning import Regression\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn import datasets\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "X, y = boston.data, boston.target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standard = StandardScaler()\n",
    "standard.fit(X_train)\n",
    "X_train_standard = standard.transform(X_train)\n",
    "X_test_standard = standard.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class module_net(nn.Module):\n",
    "    def __init__(self, num_input, num_hidden, num_output):\n",
    "        super(module_net, self).__init__()\n",
    "        self.layer1 = nn.Linear(num_input, num_hidden)\n",
    "\n",
    "        self.layer2 = nn.ReLU()\n",
    "\n",
    "        self.layer3 = nn.Linear(num_hidden, num_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = X_train_standard.shape[1]\n",
    "num_hidden = 32\n",
    "num_output = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = module_net(num_input, num_hidden, num_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 计算 prediction\n",
    "def calculate_pred(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train, X_test, y_test)\n",
    "    pred = model.predict(X_test)\n",
    "    return pred\n",
    "\n",
    "# 构造符合 贝叶斯优化 的函数\n",
    "def bayes_reg(dropout, weight_decay, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    # 自定义参数, 这里采用的是 “学习率衰减” 的方法，如传入list，为梯度衰减，反之为正常lr。\n",
    "    reg = Regression(net, learning_rate=[1e-3, 1e-5, 1e-7], \n",
    "                     dropout=dropout, weight_decay=weight_decay,\n",
    "                     epoch=2000, batch_size=128)\n",
    "    \n",
    "    r2 = r2_score(y_test, calculate_pred(reg, X_train, y_train, X_test, y_test))\n",
    "    return r2\n",
    "\n",
    "def optimize_reg(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Apply Bayesian Optimization to Random Forest parameters.\"\"\"\n",
    "    def reg_bayes(dropout, weight_decay):\n",
    "        \"\"\"Wrapper of RandomForest cross validation.\n",
    "\n",
    "        Notice how we ensure n_estimators and min_samples_split are casted\n",
    "        to integer before we pass them along. Moreover, to avoid max_features\n",
    "        taking values outside the (0, 1) range, we also ensure it is capped\n",
    "        accordingly.\n",
    "        \"\"\"\n",
    "        return bayes_reg(\n",
    "            dropout=dropout,\n",
    "            weight_decay=weight_decay,\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_test=X_test,\n",
    "            y_test=y_test,\n",
    "        )\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=reg_bayes,\n",
    "        pbounds={\n",
    "            \"dropout\": (0, 0.5),\n",
    "            \"weight_decay\": (1e-6, 1e-7),\n",
    "        },\n",
    "        random_state=1234,\n",
    "        verbose=2\n",
    "    )\n",
    "    optimizer.maximize(n_iter=3, init_points=2)\n",
    "\n",
    "    print(\"Final result:\", optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |  dropout  | weight... |\n",
      "-------------------------------------------------\n",
      "Now we're using the CPU\n",
      "The error changes within 0.01\n",
      "Training... epoch: 1090, loss: 1.5363640785217285\n",
      "\u001b[1;35m Testing... epoch: 1090, loss: 28.518508911132812 \u001b[0m!\n",
      "Now learning rate is : 1e-05\n",
      "The error changes within 0.001\n",
      "Training... epoch: 1110, loss: 1.529030442237854\n",
      "\u001b[1;35m Testing... epoch: 1110, loss: 28.51602554321289 \u001b[0m!\n",
      "Now learning rate is : 1e-07\n",
      "The error changes within 0.0001\n",
      "Training... epoch: 1130, loss: 1.5289645195007324\n",
      "\u001b[1;35m Testing... epoch: 1130, loss: 28.516002655029297 \u001b[0m!\n",
      "The meaning of the loop is not big, stop!!\n",
      "Training completed!!! Time consuming: 2.109017848968506\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7275  \u001b[0m | \u001b[0m 0.09576 \u001b[0m | \u001b[0m 4.401e-0\u001b[0m |\n",
      "Now we're using the CPU\n",
      "The error changes within 0.01\n",
      "Training... epoch: 298, loss: 0.6897491812705994\n",
      "\u001b[1;35m Testing... epoch: 298, loss: 23.770870208740234 \u001b[0m!\n",
      "Now learning rate is : 1e-05\n",
      "The error changes within 0.001\n",
      "Training... epoch: 318, loss: 0.679871141910553\n",
      "\u001b[1;35m Testing... epoch: 318, loss: 23.76491928100586 \u001b[0m!\n",
      "Now learning rate is : 1e-07\n",
      "The error changes within 0.0001\n",
      "Training... epoch: 338, loss: 0.6797659993171692\n",
      "\u001b[1;35m Testing... epoch: 338, loss: 23.7648983001709 \u001b[0m!\n",
      "The meaning of the loop is not big, stop!!\n",
      "Training completed!!! Time consuming: 0.6182761192321777\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7729  \u001b[0m | \u001b[95m 0.2189  \u001b[0m | \u001b[95m 2.932e-0\u001b[0m |\n",
      "Now we're using the CPU\n",
      "The error changes within 0.01\n",
      "Training... epoch: 264, loss: 0.6823970079421997\n",
      "\u001b[1;35m Testing... epoch: 264, loss: 20.59306526184082 \u001b[0m!\n",
      "Now learning rate is : 1e-05\n",
      "The error changes within 0.001\n",
      "Training... epoch: 284, loss: 0.6778711676597595\n",
      "\u001b[1;35m Testing... epoch: 284, loss: 20.604934692382812 \u001b[0m!\n",
      "Now learning rate is : 1e-07\n",
      "The error changes within 0.0001\n",
      "Training... epoch: 304, loss: 0.6778171062469482\n",
      "\u001b[1;35m Testing... epoch: 304, loss: 20.60490608215332 \u001b[0m!\n",
      "The meaning of the loop is not big, stop!!\n",
      "Training completed!!! Time consuming: 0.5556261539459229\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.8031  \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 1e-06   \u001b[0m |\n",
      "Now we're using the CPU\n",
      "The error changes within 0.01\n",
      "Training... epoch: 204, loss: 0.9152916669845581\n",
      "\u001b[1;35m Testing... epoch: 204, loss: 22.13222885131836 \u001b[0m!\n",
      "Now learning rate is : 1e-05\n",
      "The error changes within 0.001\n",
      "Training... epoch: 233, loss: 0.9021779298782349\n",
      "\u001b[1;35m Testing... epoch: 233, loss: 22.158023834228516 \u001b[0m!\n",
      "Now learning rate is : 1e-07\n",
      "The error changes within 0.0001\n",
      "Training... epoch: 253, loss: 0.9020627737045288\n",
      "\u001b[1;35m Testing... epoch: 253, loss: 22.158023834228516 \u001b[0m!\n",
      "The meaning of the loop is not big, stop!!\n",
      "Training completed!!! Time consuming: 0.4951589107513428\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7882  \u001b[0m | \u001b[0m 0.4074  \u001b[0m | \u001b[0m 1e-06   \u001b[0m |\n",
      "Now we're using the CPU\n",
      "The error changes within 0.01\n",
      "Training... epoch: 352, loss: 1.0007257461547852\n",
      "\u001b[1;35m Testing... epoch: 352, loss: 22.354549407958984 \u001b[0m!\n",
      "Now learning rate is : 1e-05\n",
      "The error changes within 0.001\n",
      "Training... epoch: 372, loss: 0.986138105392456\n",
      "\u001b[1;35m Testing... epoch: 372, loss: 22.35755729675293 \u001b[0m!\n",
      "Now learning rate is : 1e-07\n",
      "The error changes within 0.0001\n",
      "Training... epoch: 392, loss: 0.9859991669654846\n",
      "\u001b[1;35m Testing... epoch: 392, loss: 22.357574462890625 \u001b[0m!\n",
      "The meaning of the loop is not big, stop!!\n",
      "Training completed!!! Time consuming: 0.748790979385376\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7863  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1e-06   \u001b[0m |\n",
      "=================================================\n",
      "Final result: {'target': 0.8030737950540225, 'params': {'dropout': 0.4999982062177392, 'weight_decay': 1e-06}}\n"
     ]
    }
   ],
   "source": [
    "optimize_reg(X_train_standard, y_train, X_test_standard, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
